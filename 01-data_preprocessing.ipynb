{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torchtext.data import TabularDataset\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re\n",
    "from torchtext.data import Iterator, BucketIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "development = True\n",
    "use_cuda = True\n",
    "sample_data_folder = r'cnndm-pj/'\n",
    "\n",
    "MIN_LEN_X = 10\n",
    "MIN_LEN_Y = 10\n",
    "MAX_LEN_X = 400\n",
    "MAX_LEN_Y = 100\n",
    "MIN_NUM_X = 1\n",
    "MAX_NUM_X = 1\n",
    "MAX_NUM_Y = None\n",
    "W_LS = \"<s>\"\n",
    "W_RS = \"</s>\"\n",
    "SUMM_BEGIN_TOKEN = r\"-lrb- .* -rrb-\"\n",
    "PRETRAINED_VECTOR = 'glove.6B.200d' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "        torch.device(\"cuda\")\n",
    "        if use_cuda and torch.cuda.is_available()\n",
    "        else torch.device(\"cpu\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lines(d_path, f_name):\n",
    "    lines = []\n",
    "    f_path = os.path.join(d_path , f_name)\n",
    "    with open(f_path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc='Processing file...'):\n",
    "            line = line.strip(\"\\n\").lower()\n",
    "            fs = line.split(\"<summ-content>\")\n",
    "            if len(fs) == 2:\n",
    "                xy_tuple = get_xy_tuple(fs[1], fs[0])\n",
    "            else:\n",
    "                print(\"ERROR:\" + line)\n",
    "                continue\n",
    "            if xy_tuple != None:\n",
    "                lines.append(xy_tuple)\n",
    "    return lines\n",
    "\n",
    "def get_xy_tuple(cont, head):\n",
    "    x = read_cont(cont)\n",
    "    y = read_head(head)\n",
    "\n",
    "    if x != None and y != None:\n",
    "        return (x, y)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def read_cont(f_cont):\n",
    "    f_cont = re.sub(SUMM_BEGIN_TOKEN,'', f_cont)\n",
    "    f_cont = f_cont.replace(\"--\",\"\")\n",
    "    f_cont = f_cont.replace(\"-lrb-\",\"\").replace(\"-rrb-\",\"\")\n",
    "    words = f_cont.split()\n",
    "    num_words = len(words)\n",
    "    return f_cont if num_words >= MIN_LEN_X and num_words <= MAX_LEN_X+1 else None\n",
    "\n",
    "def read_head(f_head):\n",
    "    sents = abstract2sents(f_head)\n",
    "    line = ' '.join(sents)\n",
    "    words = line.split()\n",
    "    num_words = len(words)   \n",
    "    return line if num_words >= MIN_LEN_Y and num_words <= MAX_LEN_Y+1  else None\n",
    "\n",
    "def abstract2sents(abstract):\n",
    "    cur = 0\n",
    "    sents = []\n",
    "    while True:\n",
    "        try:\n",
    "            start_p = abstract.index(W_LS, cur)\n",
    "            end_p = abstract.index(W_RS, start_p + 1)\n",
    "            cur = end_p + len(W_RS)\n",
    "            sents.append(abstract[start_p+len(W_LS):end_p])\n",
    "        except ValueError as e: # no more sentences\n",
    "            return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path = 'cnndm-pj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec6687aa6e64ad9a90ba99664faca71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Processing file...', max=1, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007f782a966f4c69968fcd4d56206bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Processing file...', max=1, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecf0e4cd94f46c398cc2c3b371c9935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Processing file...', max=1, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print (\"train set...\")\n",
    "train_xy_list = load_lines(d_path, \"train.txt\")\n",
    "\n",
    "print (\"test set...\")\n",
    "test_xy_list = load_lines(d_path, \"test.txt\")\n",
    "print (\"validation set...\")\n",
    "valid_xy_list = load_lines(d_path, \"val.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(filename, l):\n",
    "    f = open(filename, 'w', encoding='utf')\n",
    "    for t in l:\n",
    "        line = '|'.join(str(x) for x in t)\n",
    "        f.write(line + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(os.path.join(d_path,\"train_processed.txt\"), train_xy_list)\n",
    "write_file(os.path.join(d_path,\"val_processed.txt\"), valid_xy_list)\n",
    "write_file(os.path.join(d_path,\"test_processed.txt\"), test_xy_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
